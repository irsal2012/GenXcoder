<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GenXcoder Code Generation Flow Documentation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            page-break-before: always;
            font-size: 28px;
            margin-top: 40px;
        }
        
        h1:first-of-type {
            page-break-before: auto;
            text-align: center;
            margin-top: 0;
        }
        
        h2 {
            color: #34495e;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 5px;
            margin-top: 30px;
            font-size: 22px;
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 25px;
            font-size: 18px;
        }
        
        h4 {
            color: #7f8c8d;
            margin-top: 20px;
            font-size: 16px;
        }
        
        code {
            background-color: #f8f9fa;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
            color: #e74c3c;
        }
        
        pre {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.85em;
            line-height: 1.4;
        }
        
        pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
        
        blockquote {
            border-left: 4px solid #3498db;
            margin: 20px 0;
            padding-left: 20px;
            color: #7f8c8d;
            font-style: italic;
        }
        
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        
        table th,
        table td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        
        table th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        
        .toc {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .toc ul {
            list-style-type: none;
            padding-left: 0;
        }
        
        .toc li {
            margin: 8px 0;
        }
        
        .toc a {
            text-decoration: none;
            color: #3498db;
            font-weight: 500;
        }
        
        .toc a:hover {
            text-decoration: underline;
        }
        
        .highlight {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        
        .architecture-diagram {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.8em;
            overflow-x: auto;
        }
        
        .feature-list {
            background-color: #e8f5e8;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 15px 0;
        }
        
        .feature-list ul {
            margin: 0;
            padding-left: 20px;
        }
        
        .tech-stack {
            background-color: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            margin: 15px 0;
        }
        
        .tech-stack ul {
            margin: 0;
            padding-left: 20px;
        }
        
        @media print {
            body {
                font-size: 11px;
                line-height: 1.4;
            }
            
            h1 {
                font-size: 20px;
                margin-top: 20px;
            }
            
            h2 {
                font-size: 16px;
                margin-top: 15px;
            }
            
            h3 {
                font-size: 14px;
                margin-top: 12px;
            }
            
            pre {
                font-size: 9px;
                padding: 10px;
            }
            
            .page-break {
                page-break-before: always;
            }
            
            .no-break {
                page-break-inside: avoid;
            }
        }
        
        .document-header {
            text-align: center;
            margin-bottom: 40px;
            padding: 30px 0;
            border-bottom: 2px solid #3498db;
        }
        
        .document-title {
            font-size: 32px;
            color: #2c3e50;
            margin-bottom: 10px;
        }
        
        .document-subtitle {
            font-size: 18px;
            color: #7f8c8d;
            margin-bottom: 20px;
        }
        
        .document-meta {
            font-size: 14px;
            color: #95a5a6;
        }
        
        .conclusion {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 20px;
            margin: 30px 0;
        }
        
        .document-footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px 0;
            border-top: 2px solid #ecf0f1;
            color: #7f8c8d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="document-header">
        <h1 class="document-title">GenXcoder Code Generation Flow Documentation</h1>
        <p class="document-subtitle">Complete Technical Architecture & Implementation Guide</p>
        <div class="document-meta">
            <strong>Version:</strong> 1.0.0 | 
            <strong>Date:</strong> January 2025 | 
            <strong>Authors:</strong> GenXcoder Development Team
        </div>
    </div>

    <div class="toc">
        <h2>Table of Contents</h2>
        <ul>
            <li><a href="#executive-summary">1. Executive Summary</a></li>
            <li><a href="#system-overview">2. System Overview</a></li>
            <li><a href="#agent-execution-details">3. Agent Execution Details</a></li>
            <li><a href="#iterative-code-improvement-system">4. Iterative Code Improvement System</a></li>
            <li><a href="#progress-tracking-mechanism">5. Progress Tracking Mechanism</a></li>
            <li><a href="#result-storage-system">6. Result Storage System</a></li>
            <li><a href="#agent-factory-pattern">7. Agent Factory Pattern</a></li>
            <li><a href="#event-driven-architecture">8. Event-Driven Architecture</a></li>
            <li><a href="#complete-data-flow">9. Complete Data Flow</a></li>
            <li><a href="#performance-optimizations">10. Performance Optimizations</a></li>
            <li><a href="#technical-specifications">11. Technical Specifications</a></li>
            <li><a href="#code-examples">12. Code Examples</a></li>
            <li><a href="#best-practices">13. Best Practices</a></li>
        </ul>
    </div>

    <h1 id="executive-summary">Executive Summary</h1>

    <p>GenXcoder is a sophisticated AI-powered code generation platform that transforms user requirements into production-ready applications through a multi-agent pipeline system. The platform leverages specialized AI agents, real-time progress tracking, and event-driven architecture to deliver comprehensive software solutions including code, tests, documentation, and deployment configurations.</p>

    <div class="feature-list">
        <h3>Key Features:</h3>
        <ul>
            <li><strong>Multi-Agent Pipeline:</strong> 7 specialized AI agents working in sequence</li>
            <li><strong>Real-time Progress Tracking:</strong> Live updates with intelligent polling</li>
            <li><strong>Event-Driven Communication:</strong> Decoupled agent coordination</li>
            <li><strong>Dynamic Agent Creation:</strong> Factory pattern with auto-discovery</li>
            <li><strong>Comprehensive Output:</strong> Code, tests, docs, and deployment configs</li>
            <li><strong>Production-Ready Code:</strong> PEP 8 compliant with type hints and error handling</li>
        </ul>
    </div>

    <h1 id="system-overview">System Overview</h1>

    <h2>Architecture Components</h2>

    <div class="architecture-diagram">
<pre>
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend      │    │   Backend       │    │  Agent Service  │
│   (React/TS)    │◄──►│   (FastAPI)     │◄──►│   (FastAPI)     │
│                 │    │                 │    │                 │
│ - UI Components │    │ - Project API   │    │ - Agent Manager │
│ - Progress      │    │ - File Storage  │    │ - Event Bus     │
│ - Results       │    │ - History       │    │ - Agent Factory │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
                    ┌─────────────────┐
                    │  MCP Gateway    │
                    │  (TypeScript)   │
                    │                 │
                    │ - Tool Execution│
                    │ - External APIs │
                    └─────────────────┘
</pre>
    </div>

    <div class="tech-stack">
        <h3>Technology Stack</h3>
        <ul>
            <li><strong>Frontend:</strong> React 18, TypeScript, Vite, TailwindCSS</li>
            <li><strong>Backend:</strong> Python 3.11+, FastAPI, Pydantic</li>
            <li><strong>Agent Service:</strong> Python 3.11+, AutoGen, AsyncIO</li>
            <li><strong>MCP Gateway:</strong> Node.js, TypeScript</li>
            <li><strong>Storage:</strong> File System + In-Memory</li>
            <li><strong>Communication:</strong> HTTP REST APIs, Server-Sent Events</li>
        </ul>
    </div>

    <h1 id="agent-execution-details">Agent Execution Details</h1>

    <h2>Agent Factory Pattern Implementation</h2>

    <p>The system uses a sophisticated factory pattern for dynamic agent creation and management:</p>

    <h3>Auto-Discovery Mechanism</h3>
    <pre><code>def auto_discover_agents(self) -> int:
    """Automatically discover and register all agent classes."""
    discovered_count = 0
    
    import agents
    for importer, modname, ispkg in pkgutil.iter_modules(agents.__path__):
        if modname == 'base' or modname.startswith('__'):
            continue
        
        module = importlib.import_module(f'agents.{modname}')
        
        for attr_name in dir(module):
            attr = getattr(module, attr_name)
            
            if (isinstance(attr, type) and 
                issubclass(attr, BaseAgent) and 
                attr != BaseAgent):
                
                self.register_agent(attr)
                discovered_count += 1
    
    return discovered_count</code></pre>

    <h3>Agent Configuration Types</h3>
    <ul>
        <li><strong>STANDARD:</strong> Balanced LLM settings for general tasks</li>
        <li><strong>CODING:</strong> Optimized for code generation (higher creativity, longer context)</li>
        <li><strong>REVIEW:</strong> Focused on analysis and critique</li>
        <li><strong>CREATIVE:</strong> Enhanced for documentation and UI design</li>
    </ul>

    <h2>Individual Agent Specializations</h2>

    <h3>1. Requirement Analyst Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Parses user input, structures requirements, suggests architecture</li>
        <li><strong>Config Type:</strong> STANDARD</li>
        <li><strong>Input:</strong> Raw user requirements</li>
        <li><strong>Output:</strong> Structured requirements document with technical specifications</li>
        <li><strong>Processing Time:</strong> 30-60 seconds</li>
    </ul>

    <h3>2. Python Coder Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Converts requirements into production-ready Python code</li>
        <li><strong>Config Type:</strong> CODING</li>
        <li><strong>Intelligence Features:</strong>
            <ul>
                <li>Analyzes requirements to determine application type</li>
                <li>Generates appropriate code structure (Calculator, Todo, Web API, GUI, Data Analysis)</li>
                <li>Implements PEP 8 compliance, type hints, comprehensive docstrings</li>
                <li>Includes proper error handling and logging</li>
            </ul>
        </li>
        <li><strong>Output:</strong> Complete Python modules with main code, tests, and requirements.txt</li>
        <li><strong>Processing Time:</strong> 2-5 minutes</li>
    </ul>

    <h3>3. Code Reviewer Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Reviews generated code for quality, security, and best practices</li>
        <li><strong>Config Type:</strong> REVIEW</li>
        <li><strong>Analysis Areas:</strong>
            <ul>
                <li>SOLID principles adherence</li>
                <li>Security vulnerability scanning</li>
                <li>Performance optimization suggestions</li>
                <li>Code maintainability assessment</li>
            </ul>
        </li>
        <li><strong>Processing Time:</strong> 1-2 minutes</li>
    </ul>

    <h3>4. Test Generator Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Creates comprehensive test suites</li>
        <li><strong>Config Type:</strong> CODING</li>
        <li><strong>Execution Mode:</strong> Parallel with Code Reviewer</li>
        <li><strong>Test Types:</strong>
            <ul>
                <li>Unit tests with pytest</li>
                <li>Integration tests</li>
                <li>Edge case coverage</li>
                <li>Mock implementations</li>
            </ul>
        </li>
        <li><strong>Processing Time:</strong> 1-3 minutes</li>
    </ul>

    <h3>5. Documentation Writer Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Generates comprehensive documentation</li>
        <li><strong>Config Type:</strong> CREATIVE</li>
        <li><strong>Output Components:</strong>
            <ul>
                <li>README.md with setup instructions</li>
                <li>API documentation</li>
                <li>Usage examples</li>
                <li>Architecture overview</li>
            </ul>
        </li>
        <li><strong>Processing Time:</strong> 1-2 minutes</li>
    </ul>

    <h3>6. Deployment Engineer Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Creates deployment configurations</li>
        <li><strong>Config Type:</strong> STANDARD</li>
        <li><strong>Generated Files:</strong>
            <ul>
                <li>Dockerfile</li>
                <li>docker-compose.yml</li>
                <li>Deployment scripts</li>
                <li>Environment configurations</li>
            </ul>
        </li>
        <li><strong>Processing Time:</strong> 30-60 seconds</li>
    </ul>

    <h3>7. UI Designer Agent</h3>
    <ul>
        <li><strong>Purpose:</strong> Creates Streamlit user interfaces</li>
        <li><strong>Config Type:</strong> CREATIVE</li>
        <li><strong>Special Handling:</strong> Longest execution time, requires extended timeouts</li>
        <li><strong>Output:</strong> Complete Streamlit application with interactive components</li>
        <li><strong>Processing Time:</strong> 3-8 minutes</li>
    </ul>

    <h2>Pipeline Execution Order</h2>

    <div class="architecture-diagram">
<pre>
Requirement Analyst
        ↓
Python Coder
        ↓
    ┌───────────────┐
    ↓               ↓
Code Reviewer   Test Generator
    ↓               ↓
Documentation Writer
        ↓
Deployment Engineer
        ↓
UI Designer
</pre>
    </div>

    <h1 id="iterative-code-improvement-system">Iterative Code Improvement System</h1>

    <h2>Overview</h2>

    <p>GenXcoder features an advanced <strong>iterative code improvement system</strong> that enables feedback-driven loops between agents to produce the highest quality code possible. The system allows the Python coder and code reviewer agents to collaborate iteratively, with the reviewer providing structured feedback and the coder making targeted improvements until quality thresholds are met.</p>

    <h2>Key Components</h2>

    <h3>1. Structured Feedback System</h3>
    <p>The system uses comprehensive feedback structures to enable precise communication between agents:</p>

    <pre><code>@dataclass
class StructuredFeedback:
    """Structured feedback from reviewer agents."""
    quality_score: float  # 0-100 overall quality score
    quality_metrics: QualityMetrics
    issues: List[FeedbackIssue] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    positive_aspects: List[str] = field(default_factory=list)
    iteration_number: int = 1
    reviewer_agent: str = ""
    timestamp: Optional[str] = None</code></pre>

    <h3>2. Quality Metrics Assessment</h3>
    <p>Comprehensive quality evaluation across multiple dimensions:</p>

    <div class="feature-list">
        <ul>
            <li><strong>Complexity Score</strong> (0-100): Code complexity and structure analysis</li>
            <li><strong>Maintainability Score</strong> (0-100): Ease of maintenance and modification</li>
            <li><strong>Readability Score</strong> (0-100): Code clarity and documentation quality</li>
            <li><strong>Test Coverage</strong> (0-100): Testability and test presence estimation</li>
            <li><strong>Performance Score</strong> (0-100): Efficiency and optimization assessment</li>
            <li><strong>Security Score</strong> (0-100): Security best practices adherence</li>
        </ul>
    </div>

    <h3>3. Issue Categorization</h3>
    <p>Structured issue identification with severity levels:</p>

    <ul>
        <li><strong>Critical</strong>: Security vulnerabilities, major bugs</li>
        <li><strong>High</strong>: Performance problems, architecture concerns</li>
        <li><strong>Medium</strong>: Style violations, minor improvements</li>
        <li><strong>Low</strong>: Cosmetic issues, suggestions</li>
        <li><strong>Info</strong>: General information and tips</li>
    </ul>

    <h2>Iterative Pipeline Configuration</h2>

    <h3>Enhanced Pipeline Steps</h3>
    <pre><code># Iterative development pipeline configuration
steps:
  - agent_type: requirement_analyst
    config_type: standard
    execution_mode: sequential

  - agent_type: iterative_coding_loop
    config_type: coding
    execution_mode: iterative
    depends_on: [requirement_analyst]
    iterative_config:
      improver_agent: python_coder
      evaluator_agent: code_reviewer
      max_iterations: 3
      quality_threshold: 85.0
      timeout_per_iteration: 300

  - agent_type: test_generator
    depends_on: [iterative_coding_loop]
    execution_mode: parallel</code></pre>

    <h3>Configuration Parameters</h3>
    <ul>
        <li><strong><code>improver_agent</code></strong>: Agent that generates/improves content (e.g., python_coder)</li>
        <li><strong><code>evaluator_agent</code></strong>: Agent that evaluates and provides feedback (e.g., code_reviewer)</li>
        <li><strong><code>max_iterations</code></strong>: Maximum number of improvement cycles (default: 3)</li>
        <li><strong><code>quality_threshold</code></strong>: Minimum quality score to exit loop (default: 85.0)</li>
        <li><strong><code>timeout_per_iteration</code></strong>: Timeout per iteration in seconds (default: 300)</li>
    </ul>

    <h2>Execution Flow</h2>

    <h3>1. Initial Code Generation</h3>
    <div class="architecture-diagram">
<pre>
User Requirements → Requirement Analyst → Python Coder (Initial Code)
</pre>
    </div>

    <h3>2. Iterative Improvement Loop</h3>
    <div class="architecture-diagram">
<pre>
┌─────────────────────────────────────────────────────────────┐
│                    Iterative Loop                           │
│                                                             │
│  Python Coder → Code Reviewer → Quality Assessment         │
│       ↑              ↓              ↓                      │
│       │         Structured      Quality Score              │
│       │         Feedback        ≥ Threshold?               │
│       │              ↓              ↓                      │
│       └──────── Apply Fixes ←── No (Continue)              │
│                                     ↓                      │
│                                Yes (Exit)                  │
└─────────────────────────────────────────────────────────────┘
</pre>
    </div>

    <h3>3. Iteration Process</h3>
    <ol>
        <li><strong>Code Generation</strong>: Python coder generates or improves code</li>
        <li><strong>Quality Review</strong>: Code reviewer analyzes code and assigns quality scores</li>
        <li><strong>Feedback Processing</strong>: Structured feedback with specific improvement suggestions</li>
        <li><strong>Threshold Check</strong>: Compare quality score against configured threshold</li>
        <li><strong>Improvement Application</strong>: Python coder applies targeted fixes based on feedback</li>
        <li><strong>Loop Continuation</strong>: Repeat until threshold met or max iterations reached</li>
    </ol>

    <h2>Code Improvement Strategies</h2>

    <h3>Security Enhancements</h3>
    <pre><code># Before (flagged by reviewer)
user_input = eval(input("Enter expression: "))

# After (improved by coder)
import ast
try:
    user_input = ast.literal_eval(input("Enter expression: "))
except (ValueError, SyntaxError) as e:
    logger.error(f"Invalid input: {e}")
    user_input = None</code></pre>

    <h3>Documentation Improvements</h3>
    <pre><code># Before (missing docstrings)
def calculate(a, b, op):
    if op == '+':
        return a + b

# After (comprehensive documentation)
def calculate(a: Union[int, float], b: Union[int, float], op: str) -> Union[int, float]:
    """Perform arithmetic calculation between two numbers.
    
    Args:
        a: First operand
        b: Second operand
        op: Operation to perform ('+', '-', '*', '/')
        
    Returns:
        Result of the arithmetic operation
        
    Raises:
        ValueError: If operation is not supported
        ZeroDivisionError: If division by zero is attempted
    """
    if op == '+':
        return a + b</code></pre>

    <h3>Performance Optimizations</h3>
    <pre><code># Before (inefficient loop pattern)
for i in range(len(items)):
    process(items[i])

# After (optimized iteration)
for item in items:
    process(item)</code></pre>

    <h2>Quality Assessment Examples</h2>

    <h3>High-Quality Code (Score: 92/100)</h3>
    <pre><code>"""
High-quality calculator module with comprehensive error handling,
documentation, and type hints.
"""

import logging
from typing import Union, Dict, Any
from decimal import Decimal, InvalidOperation

logger = logging.getLogger(__name__)

class Calculator:
    """Professional calculator with robust error handling."""
    
    def __init__(self) -> None:
        """Initialize calculator with operation history."""
        self.history: List[Dict[str, Any]] = []
        logger.info("Calculator initialized")
    
    def add(self, a: Union[int, float, Decimal], b: Union[int, float, Decimal]) -> Union[int, float, Decimal]:
        """Add two numbers with comprehensive error handling."""
        try:
            result = a + b
            self._log_operation(a, b, '+', result)
            return result
        except (TypeError, OverflowError) as e:
            logger.error(f"Addition failed: {e}")
            raise ValueError(f"Cannot add {a} and {b}: {e}")</code></pre>

    <h3>Feedback for Improvement (Score: 65/100)</h3>
    <pre><code>{
  "quality_score": 65.0,
  "issues": [
    {
      "type": "security",
      "severity": "critical",
      "message": "Use of eval() function poses security risk",
      "suggestion": "Replace eval() with ast.literal_eval() for safe evaluation"
    },
    {
      "type": "maintainability",
      "severity": "medium",
      "message": "Functions lack docstrings",
      "suggestion": "Add comprehensive docstrings with Args, Returns, and Raises sections"
    }
  ],
  "suggestions": [
    "Add type hints for better code clarity",
    "Implement proper error handling with try-catch blocks",
    "Consider using logging instead of print statements"
  ]
}</code></pre>

    <h2>Benefits of Iterative System</h2>

    <h3>1. Quality Assurance</h3>
    <ul>
        <li><strong>Guaranteed Standards</strong>: Code must meet quality thresholds before proceeding</li>
        <li><strong>Comprehensive Analysis</strong>: Multi-dimensional quality assessment</li>
        <li><strong>Continuous Improvement</strong>: Each iteration produces better code</li>
    </ul>

    <h3>2. Automated Code Review</h3>
    <ul>
        <li><strong>Consistent Standards</strong>: Automated application of coding best practices</li>
        <li><strong>Security Focus</strong>: Automatic detection and fixing of security vulnerabilities</li>
        <li><strong>Performance Optimization</strong>: Identification and resolution of performance issues</li>
    </ul>

    <h3>3. Learning and Adaptation</h3>
    <ul>
        <li><strong>Pattern Recognition</strong>: System learns from feedback patterns</li>
        <li><strong>Improvement Tracking</strong>: Detailed metrics on quality improvements</li>
        <li><strong>Trend Analysis</strong>: Quality improvement trends across iterations</li>
    </ul>

    <h3>4. Transparency and Monitoring</h3>
    <ul>
        <li><strong>Real-time Progress</strong>: Live updates on iteration progress</li>
        <li><strong>Quality Metrics</strong>: Detailed quality scores and improvement trends</li>
        <li><strong>Iteration History</strong>: Complete record of improvements made</li>
    </ul>

    <h2>Integration with Existing Pipeline</h2>

    <p>The iterative system seamlessly integrates with the existing GenXcoder pipeline:</p>

    <div class="architecture-diagram">
<pre>
Requirement Analyst
        ↓
┌─────────────────────┐
│ Iterative Loop      │
│ ┌─────────────────┐ │
│ │ Python Coder    │ │ ← Iteration 1
│ │       ↓         │ │
│ │ Code Reviewer   │ │
│ └─────────────────┘ │
│ ┌─────────────────┐ │
│ │ Python Coder    │ │ ← Iteration 2
│ │       ↓         │ │
│ │ Code Reviewer   │ │
│ └─────────────────┘ │
│ ┌─────────────────┐ │
│ │ Python Coder    │ │ ← Iteration 3
│ │       ↓         │ │
│ │ Code Reviewer   │ │
│ └─────────────────┘ │
└─────────────────────┘
        ↓
Test Generator (parallel)
        ↓
Documentation Writer (parallel)
        ↓
Deployment Engineer
        ↓
UI Designer
</pre>
    </div>

    <h2>Performance Considerations</h2>

    <h3>Timeout Management</h3>
    <ul>
        <li><strong>Per-iteration timeouts</strong>: Prevent infinite loops</li>
        <li><strong>Adaptive timeouts</strong>: Longer timeouts for complex improvements</li>
        <li><strong>Graceful degradation</strong>: Return best available code if timeouts occur</li>
    </ul>

    <h3>Resource Optimization</h3>
    <ul>
        <li><strong>Parallel processing</strong>: Multiple improvement strategies applied simultaneously</li>
        <li><strong>Caching</strong>: Reuse of analysis results across iterations</li>
        <li><strong>Memory management</strong>: Efficient handling of iteration history</li>
    </ul>

    <h2>Future Enhancements</h2>

    <h3>Planned Features</h3>
    <ol>
        <li><strong>Multi-Agent Loops</strong>: Support for more than two agents in improvement cycles</li>
        <li><strong>Adaptive Thresholds</strong>: Dynamic quality threshold adjustment based on project complexity</li>
        <li><strong>Learning System</strong>: Machine learning-based improvement pattern recognition</li>
        <li><strong>Custom Metrics</strong>: User-defined quality metrics and scoring systems</li>
        <li><strong>Visual Progress</strong>: Real-time visualization of quality improvements</li>
    </ol>

    <h3>Integration Opportunities</h3>
    <ol>
        <li><strong>IDE Integration</strong>: Real-time code improvement suggestions in development environments</li>
        <li><strong>CI/CD Pipelines</strong>: Automated quality gates in deployment workflows</li>
        <li><strong>Code Review Tools</strong>: Integration with existing code review platforms</li>
        <li><strong>Quality Dashboards</strong>: Centralized monitoring of code quality trends</li>
    </ol>

    <h1 id="progress-tracking-mechanism">Progress Tracking Mechanism</h1>

    <h2>Frontend Progress Tracker</h2>

    <h3>Intelligent Polling System</h3>
    <pre><code>const { data: progress } = useQuery&lt;ProjectProgress&gt;({
  queryKey: ['project-progress', projectId],
  queryFn: () => {
    const extendedTimeout = uiGenerationDetected || lastProgressPercentage > 85;
    return apiClient.getProjectProgress(projectId, extendedTimeout);
  },
  refetchInterval: (query) => {
    if (query.state.data?.is_completed) return false;
    if (uiGenerationDetected) return 3000; // Slower for UI generation
    return 1000; // Fast updates for other steps
  },
  retry: (failureCount, error) => {
    const maxRetries = uiGenerationDetected ? 10 : 5;
    return failureCount < maxRetries;
  }
});</code></pre>

    <h3>Smart Detection Features</h3>
    <ul>
        <li><strong>UI Generation Detection:</strong> Automatically detects when UI Designer agent starts</li>
        <li><strong>Extended Timeout Handling:</strong> Increases timeouts for long-running operations</li>
        <li><strong>Fallback Completion Check:</strong> Secondary mechanism if primary polling fails</li>
        <li><strong>Retry Logic:</strong> Exponential backoff with configurable max retries</li>
    </ul>

    <h3>Visual Progress Components</h3>
    <ul>
        <li><strong>Step-by-Step Visualization:</strong> 7 distinct pipeline steps with icons and colors</li>
        <li><strong>Real-time Percentage Updates:</strong> Granular progress within each step</li>
        <li><strong>Status Indicators:</strong> Pending (○), Running (⟳), Completed (✓), Failed (✗)</li>
        <li><strong>Debug Information:</strong> Expandable technical details for troubleshooting</li>
    </ul>

    <h2>Backend Progress Management</h2>

    <h3>Progress Data Structure</h3>
    <pre><code>self._progress_data = {
    'total_steps': len(pipeline_steps),
    'completed_steps': 0,
    'failed_steps': 0,
    'progress_percentage': 0.0,
    'steps': [
        {
            'name': 'Requirements Analysis',
            'description': 'Understanding your requirements',
            'status': 'pending',
            'progress_percentage': 0,
            'agent_type': 'requirement_analyst',
            'optional': False
        },
        # ... other steps
    ],
    'elapsed_time': 0.0,
    'estimated_remaining_time': 0.0,
    'is_running': False,
    'is_completed': False,
    'has_failures': False,
    'current_step_info': None,
    'logs': []
}</code></pre>

    <h3>Time Estimation Algorithm</h3>
    <pre><code>def _update_overall_progress(self):
    """Update overall pipeline progress with time estimation."""
    total_steps = len(self._pipeline_config.steps)
    completed_steps = self._progress_data['completed_steps']
    
    # Calculate progress percentage
    progress_percentage = (completed_steps / total_steps) * 100 if total_steps > 0 else 0
    self._progress_data['progress_percentage'] = progress_percentage
    
    # Update elapsed time
    if self._start_time:
        self._progress_data['elapsed_time'] = time.time() - self._start_time
    
    # Estimate remaining time
    if completed_steps > 0 and self._start_time:
        elapsed = time.time() - self._start_time
        avg_time_per_step = elapsed / completed_steps
        remaining_steps = total_steps - completed_steps
        self._progress_data['estimated_remaining_time'] = avg_time_per_step * remaining_steps</code></pre>

    <h1 id="result-storage-system">Result Storage System</h1>

    <h2>Backend Storage Architecture</h2>

    <h3>Multi-Layer Storage Strategy</h3>
    <ol>
        <li><strong>In-Memory Storage:</strong> Fast access for active projects</li>
        <li><strong>File System Storage:</strong> Persistent storage in <code>backend/generated_projects/</code></li>
        <li><strong>History Management:</strong> Maintains project history with metadata</li>
    </ol>

    <h3>Project Data Structure</h3>
    <pre><code>project_data = {
    'project_id': 'uuid-string',
    'project_name': 'user-defined-name',
    'user_input': 'original requirements',
    'timestamp': '2024-01-01T12:00:00Z',
    'success': True,
    'execution_time': 180.5,
    'generated_files': {
        'main.py': 'python code content',
        'test_main.py': 'test code content',
        'requirements.txt': 'dependencies',
        'README.md': 'documentation',
        'Dockerfile': 'deployment config'
    },
    'code': {
        'final_code': 'concatenated main code',
        'generated_files': {...}
    },
    'documentation': {
        'readme': 'README content',
        'api_docs': 'API documentation'
    },
    'tests': {
        'test_code': 'complete test suite',
        'coverage_report': 'test coverage data'
    },
    'deployment': {
        'dockerfile': 'Docker configuration',
        'docker_compose': 'Compose file',
        'deployment_scripts': 'Shell scripts'
    },
    'ui': {
        'streamlit_app': 'Streamlit interface code'
    },
    'pipeline_metadata': {
        'execution_id': 'pipeline-uuid',
        'agent_results': {...},
        'execution_logs': [...],
        'performance_metrics': {...}
    }
}</code></pre>

    <h3>File Storage Service</h3>

    <h4>Directory Structure</h4>
    <pre><code>backend/generated_projects/
├── project-uuid-1/
│   ├── complete_project_data.json
│   ├── project_metadata.json
│   ├── main.py
│   ├── test_main.py
│   ├── requirements.txt
│   ├── README.md
│   ├── Dockerfile
│   ├── streamlit_app.py
│   └── DEPLOYMENT.md
├── project-uuid-2/
│   └── ...</code></pre>

    <h4>Data Transformation Pipeline</h4>
    <pre><code>async def save_generated_project(project_data: dict):
    """Transform agent service result format to backend format."""
    
    # Extract project information
    project_id = project_data.get('execution_id') or project_data.get('project_id')
    
    # Transform agent service result format to backend format
    transformed_data = {
        'project_id': project_id,
        'project_name': project_data.get('pipeline_name', f'project-{project_id[:8]}'),
        'user_input': project_data.get('input_data', ''),
        'timestamp': project_data.get('completed_at') or project_data.get('started_at'),
        'success': project_data.get('status') == 'completed',
        'generated_files': {},
        'code': {},
        'documentation': {},
        'tests': {},
        'deployment': {},
        'ui': {}
    }
    
    # Extract generated files from agent results
    result = project_data.get('result', {})
    for agent_name, agent_result in result.items():
        if 'generated_code' in agent_result:
            transformed_data['generated_files'].update(agent_result['generated_code'])
        
        if 'documentation' in agent_result:
            transformed_data['documentation']['readme'] = agent_result['documentation']
        
        # ... extract other components
    
    # Save using project service
    saved_path = await project_service.save_project_result(project_id, transformed_data)
    return saved_path</code></pre>

    <h1 id="agent-factory-pattern">Agent Factory Pattern</h1>

    <h2>Registration & Discovery System</h2>

    <h3>Metadata-Driven Configuration</h3>
    <pre><code>@classmethod
def get_metadata(cls) -> AgentMetadata:
    """Return agent metadata for registration and discovery."""
    return AgentMetadata(
        name="Python Coder",
        description="Generates high-quality Python code from structured requirements",
        capabilities=[
            "Python code generation",
            "Best practices implementation",
            "Type hints and documentation",
            "Error handling and logging",
            "SOLID principles adherence",
            "PEP 8 compliance",
            "Modular code design"
        ],
        config_type=ConfigType.CODING,
        dependencies=["Requirement Analyst"],
        version="2.0.0"
    )</code></pre>

    <h3>Dependency Management</h3>
    <pre><code>def get_dependency_order(self) -> List[str]:
    """Get agents in dependency order using topological sort."""
    visited = set()
    temp_visited = set()
    result = []
    
    def visit(agent_key: str):
        if agent_key in temp_visited:
            raise ValueError(f"Circular dependency detected involving {agent_key}")
        
        if agent_key not in visited:
            temp_visited.add(agent_key)
            
            metadata = self._metadata_cache.get(agent_key)
            if metadata and metadata.dependencies:
                for dep in metadata.dependencies:
                    dep_key = self._generate_agent_key(dep)
                    if dep_key in self._agents:
                        visit(dep_key)
            
            temp_visited.remove(agent_key)
            visited.add(agent_key)
            result.append(agent_key)
    
    for agent_key in self._agents.keys():
        if agent_key not in visited:
            visit(agent_key)
    
    return result</code></pre>

    <h3>Configuration Types & LLM Settings</h3>
    <pre><code>def _get_llm_config_for_type(self, config_type: ConfigType) -> Dict:
    """Get appropriate LLM configuration for the given type."""
    config_methods = {
        ConfigType.STANDARD: model_config.get_llm_config,      # Balanced settings
        ConfigType.CODING: model_config.get_coding_config,     # Higher creativity, longer context
        ConfigType.REVIEW: model_config.get_review_config,     # Focused on analysis
        ConfigType.CREATIVE: model_config.get_creative_config  # Enhanced for docs/UI
    }
    
    method = config_methods.get(config_type, model_config.get_llm_config)
    return method()</code></pre>

    <h1 id="event-driven-architecture">Event-Driven Architecture</h1>

    <h2>Event Bus System</h2>

    <h3>Event Types Hierarchy</h3>
    <pre><code>class EventType(Enum):
    """Types of events in the agent system."""
    # Agent lifecycle events
    AGENT_STARTED = "agent_started"
    AGENT_COMPLETED = "agent_completed"
    AGENT_FAILED = "agent_failed"
    AGENT_PROGRESS = "agent_progress"
    
    # Pipeline events
    PIPELINE_STARTED = "pipeline_started"
    PIPELINE_STEP_STARTED = "pipeline_step_started"
    PIPELINE_STEP_COMPLETED = "pipeline_step_completed"
    PIPELINE_COMPLETED = "pipeline_completed"
    PIPELINE_FAILED = "pipeline_failed"
    
    # Data flow events
    DATA_AVAILABLE = "data_available"
    DATA_PROCESSED = "data_processed"
    DATA_VALIDATION_FAILED = "data_validation_failed"
    
    # System events
    SYSTEM_ERROR = "system_error"
    SYSTEM_WARNING = "system_warning"
    SYSTEM_INFO = "system_info"</code></pre>

    <h3>Event Data Structure</h3>
    <pre><code>@dataclass
class AgentEvent:
    """Event data structure for agent system communication."""
    event_type: EventType
    source: str  # Agent name or system component
    timestamp: float = field(default_factory=time.time)
    data: Optional[Any] = None
    metadata: Optional[Dict[str, Any]] = None
    correlation_id: Optional[str] = None  # For tracking related events</code></pre>

    <h3>Subscription Mechanisms</h3>
    <pre><code># Direct subscription to specific event type
event_bus.subscribe(EventType.AGENT_COMPLETED, handle_completion)

# Filtered subscription with custom criteria
event_filter = EventFilter(
    event_types=[EventType.AGENT_STARTED, EventType.AGENT_COMPLETED],
    sources=["python_coder", "test_generator"],
    correlation_id="pipeline-123"
)
event_bus.subscribe_filtered(event_filter, handle_coding_events)

# Multiple event types with single callback
event_bus.subscribe_multiple(
    [EventType.PIPELINE_STARTED, EventType.PIPELINE_COMPLETED],
    handle_pipeline_lifecycle
)</code></pre>

    <h3>Async Event Processing</h3>
    <pre><code>async def publish(self, event: AgentEvent) -> int:
    """Publish an event to all subscribers."""
    async with self._lock:
        # Add to history
        self._event_history.append(event)
        
        notified_count = 0
        
        # Notify direct subscribers
        if event.event_type.value in self._subscribers:
            tasks = []
            for callback in self._subscribers[event.event_type.value]:
                if asyncio.iscoroutinefunction(callback):
                    tasks.append(callback(event))
                else:
                    tasks.append(asyncio.get_event_loop().run_in_executor(
                        None, callback, event
                    ))
                notified_count += 1
            
            # Execute all callbacks concurrently
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                # Handle any callback failures
                for result in results:
                    if isinstance(result, Exception):
                        self.logger.error(f"Callback failed: {str(result)}")
        
        return notified_count</code></pre>

    <h1 id="complete-data-flow">Complete Data Flow</h1>

    <h2>End-to-End Request Flow</h2>

    <div class="architecture-diagram">
<pre>
┌─────────────────────────────────────────────────────────────────────────────┐
│                           USER INTERACTION                                  │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  FRONTEND (React/TypeScript)                                                │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │ CodeGenerator   │    │ ProgressTracker │    │ ResultsDisplay  │         │
│  │ Component       │    │ Component       │    │ Component       │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼ HTTP POST /v1/pipelines/execute
┌─────────────────────────────────────────────────────────────────────────────┐
│  AGENT SERVICE (FastAPI)                                                    │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │ Pipeline Routes │    │ Agent Manager   │    │ Event Bus       │         │
│  │                 │    │ V2              │    │                 │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  AGENT FACTORY & PIPELINE EXECUTION                                         │
│                                                                             │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │ Agent Factory   │    │ Pipeline Config │    │ Agent Instances │         │
│  │ - Auto Discovery│    │ - YAML Config   │    │ - Specialized   │         │
│  │ - Registration  │    │ - Dependencies  │    │ - LLM Configs   │         │
│  │ - Creation      │    │ - Execution     │    │ - Processing    │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  SEQUENTIAL AGENT EXECUTION                                                  │
│                                                                             │
│  Requirement Analyst → Python Coder → Code Reviewer ┐                      │
│                                           ↓          │                      │
│                                    Test Generator ←──┘                      │
│                                           ↓                                 │
│                                Documentation Writer                         │
│                                           ↓                                 │
│                                Deployment Engineer                          │
│                                           ↓                                 │
│                                    UI Designer                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼ HTTP POST /api/v1/projects/save-generated
┌─────────────────────────────────────────────────────────────────────────────┐
│  BACKEND SERVICE (FastAPI)                                                  │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │ Project Routes  │    │ Project Service │    │ File Storage    │         │
│  │                 │    │                 │    │ Service         │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  RESULT STORAGE & ORGANIZATION                                              │
│                                                                             │
│  backend/generated_projects/project-uuid/                                   │
│  ├── complete_project_data.json                                             │
│  ├── project_metadata.json                                                  │
│  ├── main.py                                                                │
│  ├── test_main.py                                                           │
│  ├── requirements.txt                                                       │
│  ├── README.md                                                              │
│  ├── Dockerfile                                                             │
│  ├── streamlit_app.py                                                       │
│  └── DEPLOYMENT.md                                                          │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼ HTTP GET /api/v1/projects/{project_id}
┌─────────────────────────────────────────────────────────────────────────────┐
│  FRONTEND RESULTS DISPLAY                                                   │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │ Code Viewer     │    │ Documentation   │    │ Download        │         │
│  │ - Syntax        │    │ Display         │    │ Options         │         │
│  │   Highlighting  │    │ - README        │    │ - ZIP Archive   │         │
│  │ - File Tabs     │    │ - API Docs      │    │ - Individual    │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
</pre>
    </div>

    <h2>Data Transformation Points</h2>

    <ol>
        <li><strong>User Input → API Request</strong>
            <pre><code>const request: GenerateCodeRequest = {
  user_input: description.trim(),
  project_name: projectName.trim() || undefined
};</code></pre>
        </li>

        <li><strong>API Request → Pipeline Execution</strong>
            <pre><code>pipeline_execution_store[execution_id] = {
  "pipeline_name": pipeline_name,
  "status": "running",
  "input_data": request.input_data,
  "result": None
}</code></pre>
        </li>

        <li><strong>Agent Results → Backend Format</strong>
            <pre><code>transformed_data = {
  'project_id': execution_id,
  'generated_files': extract_generated_files(agent_results),
  'code': extract_code_components(agent_results),
  'documentation': extract_documentation(agent_results),
  'tests': extract_test_files(agent_results),
  'deployment': extract_deployment_configs(agent_results),
  'ui': extract_ui_components(agent_results)
}</code></pre>
        </li>

        <li><strong>Backend Storage → Frontend Display</strong>
            <pre><code>const result: ProjectResult = await apiClient.getProjectResult(projectId);
// Display code, documentation, tests, deployment configs</code></pre>
        </li>
    </ol>

    <h1 id="performance-optimizations">Performance Optimizations</h1>

    <h2>1. Parallel Execution Strategy</h2>
    <pre><code># Pipeline configuration allows parallel execution
- agent_type: code_reviewer
  execution_mode: sequential
  depends_on: [python_coder]

- agent_type: test_generator
  execution_mode: parallel  # Runs parallel with code_reviewer
  depends_on: [python_coder]</code></pre>

    <h2>2. Intelligent Caching</h2>
    <pre><code>class AgentFactory:
    def create_agent(self, agent_key: str) -> BaseAgent:
        # Check if we already have an instance (singleton pattern)
        if agent_key in self._instances:
            return self._instances[agent_key]
        
        # Create and cache new instance
        agent_instance = agent_class(llm_config)
        self._instances[agent_key] = agent_instance
        return agent_instance</code></pre>

    <h2>3. Adaptive Polling</h2>
    <pre><code>// Frontend adjusts polling frequency based on operation type
refetchInterval: (query) => {
  if (query.state.data?.is_completed) return false;
  if (uiGenerationDetected) return 3000; // Slower for UI generation
  return 1000; // Fast updates for other steps
}</code></pre>

    <h2>4. Background Processing</h2>
    <pre><code># Pipeline execution doesn't block API response
if request.async_execution:
    background_tasks.add_task(
        _execute_pipeline_background,
        execution_id,
        request.input_data,
        correlation_id,
        pipeline_name
    )
    
    return PipelineExecutionResponse(
        execution_id=execution_id,
        status="running",
        message="Pipeline execution started in background"
    )</code></pre>

    <h2>5. Event-Driven Updates</h2>
    <pre><code># Efficient real-time communication without polling overhead
await event_bus.publish(AgentEvent(
    event_type=EventType.AGENT_COMPLETED,
    source=agent_name,
    data=result,
    correlation_id=correlation_id
))</code></pre>

    <h2>6. Memory Management</h2>
    <pre><code># Automatic cleanup of old results
async def cleanup_old_results(self, max_age_days: int = 30):
    cutoff_time = datetime.now() - timedelta(days=max_age_days)
    
    # Clean up project results and history
    results_to_remove = [
        project_id for project_id, result in self.project_results.items()
        if result.get('timestamp') < cutoff_time
    ]
    
    for project_id in results_to_remove:
        del self.project_results[project_id]</code></pre>

    <h1 id="technical-specifications">Technical Specifications</h1>

    <h2>System Requirements</h2>
    <ul>
        <li><strong>Python:</strong> 3.11 or higher</li>
        <li><strong>Node.js:</strong> 18.0 or higher</li>
        <li><strong>Memory:</strong> Minimum 8GB RAM (16GB recommended)</li>
        <li><strong>Storage:</strong> 10GB free space for generated projects</li>
        <li><strong>Network:</strong> Internet connection for LLM API calls</li>
    </ul>

    <h2>API Endpoints</h2>

    <h3>Agent Service Endpoints</h3>
    <pre><code>POST   /v1/pipelines/execute              # Execute pipeline
GET    /v1/pipelines/execution/{id}/status # Get execution status
GET    /v1/pipelines/execution/{id}/stream # Stream status updates
GET    /v1/pipelines/info                 # Get pipeline information
POST   /v1/pipelines/initialize           # Initialize pipeline
POST   /v1/pipelines/validate             # Validate input
DELETE /v1/pipelines/clear                # Clear pipeline
GET    /v1/pipelines/                     # List executions
GET    /v1/agents/                        # List agents
GET    /v1/agents/{name}/                 # Get agent details
POST   /v1/agents/{name}/execute/         # Execute single agent
GET    /v1/capabilities/                  # Get capabilities</code></pre>

    <h3>Backend Service Endpoints</h3>
    <pre><code>GET    /api/v1/projects/history           # Get project history
GET    /api/v1/projects/statistics        # Get statistics
GET    /api/v1/projects/recent            # Get recent projects
GET    /api/v1/projects/search            # Search projects
GET    /api/v1/projects/{id}              # Get project result
DELETE /api/v1/projects/{id}              # Delete project
GET    /api/v1/projects/name/{name}       # Get project by name
POST   /api/v1/projects/cleanup           # Cleanup old projects
POST   /api/v1/projects/save-generated    # Save generated project
GET    /api/v1/projects/                  # List all projects</code></pre>

    <h2>Configuration Files</h2>

    <h3>Pipeline Configuration (YAML)</h3>
    <pre><code>description: Standard multi-agent development pipeline
failure_strategy: stop
global_timeout_seconds: null
max_parallel_steps: 3
metadata: null
name: default
steps:
- agent_type: requirement_analyst
  config_type: standard
  execution_mode: sequential
  optional: false
- agent_type: python_coder
  config_type: coding
  depends_on: [requirement_analyst]
  execution_mode: sequential
  optional: false
- agent_type: code_reviewer
  config_type: review
  depends_on: [python_coder]
  execution_mode: sequential
  optional: false
- agent_type: test_generator
  config_type: coding
  depends_on: [python_coder]
  execution_mode: parallel
  optional: false
- agent_type: documentation_writer
  config_type: creative
  depends_on: [code_reviewer]
  execution_mode: parallel
  optional: false
- agent_type: deployment_engineer
  config_type: standard
  depends_on: [test_generator]
  execution_mode: sequential
  optional: false
- agent_type: ui_designer
  config_type: creative
  depends_on: [documentation_writer]
  execution_mode: sequential
  optional: false
version: 1.0.0</code></pre>

    <h3>Environment Configuration</h3>
    <pre><code># Agent Service Environment
AGENT_SERVICE_PORT=8001
AGENT_SERVICE_HOST=0.0.0.0
LOG_LEVEL=INFO
MAX_CONCURRENT_PIPELINES=5
PIPELINE_TIMEOUT_SECONDS=3600

# Backend Service Environment
BACKEND_SERVICE_PORT=8000
BACKEND_SERVICE_HOST=0.0.0.0
PROJECT_STORAGE_PATH=./generated_projects
MAX_PROJECT_HISTORY=1000

# Frontend Environment
VITE_API_BASE_URL=http://localhost:8000
VITE_AGENT_SERVICE_URL=http://localhost:8001
VITE_APP_TITLE=GenXcoder</code></pre>

    <h1 id="code-examples">Code Examples</h1>

    <h2>Example 1: Calculator Application Generation</h2>

    <h3>User Input:</h3>
    <pre><code>Create a calculator application that can perform basic arithmetic operations</code></pre>

    <h3>Generated Python Code:</h3>
    <pre><code>#!/usr/bin/env python3
"""
Simple Calculator Application
Supports basic arithmetic operations: addition, subtraction, multiplication, division
"""

import logging
from typing import Union

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Calculator:
    """A simple calculator class with basic arithmetic operations."""
    
    def __init__(self):
        """Initialize the calculator."""
        logger.info("Calculator initialized")
    
    def add(self, a: Union[int, float], b: Union[int, float]) -> Union[int, float]:
        """Add two numbers."""
        result = a + b
        logger.info(f"Addition: {a} + {b} = {result}")
        return result
    
    def subtract(self, a: Union[int, float], b: Union[int, float]) -> Union[int, float]:
        """Subtract two numbers."""
        result = a - b
        logger.info(f"Subtraction: {a} - {b} = {result}")
        return result
    
    def multiply(self, a: Union[int, float], b: Union[int, float]) -> Union[int, float]:
        """Multiply two numbers."""
        result = a * b
        logger.info(f"Multiplication: {a} * {b} = {result}")
        return result
    
    def divide(self, a: Union[int, float], b: Union[int, float]) -> Union[int, float]:
        """Divide two numbers."""
        if b == 0:
            logger.error("Division by zero attempted")
            raise ValueError("Cannot divide by zero")
        
        result = a / b
        logger.info(f"Division: {a} / {b} = {result}")
        return result

def main():
    """Main function to run the calculator interactively."""
    calc = Calculator()
    
    print("Simple Calculator")
    print("Operations: +, -, *, /")
    print("Type 'quit' to exit")
    
    while True:
        try:
            user_input = input("\nEnter calculation (e.g., 5 + 3): ").strip()
            
            if user_input.lower() == 'quit':
                print("Goodbye!")
                break
            
            # Parse and execute calculation
            parts = user_input.split()
            if len(parts) != 3:
                print("Invalid format. Use: number operator number")
                continue
            
            num1 = float(parts[0])
            operator = parts[1]
            num2 = float(parts[2])
            
            if operator == '+':
                result = calc.add(num1, num2)
            elif operator == '-':
                result = calc.subtract(num1, num2)
            elif operator == '*':
                result = calc.multiply(num1, num2)
            elif operator == '/':
                result = calc.divide(num1, num2)
            else:
                print(f"Unknown operator: {operator}")
                continue
            
            print(f"Result: {result}")
            
        except ValueError as e:
            print(f"Error: {e}")
        except KeyboardInterrupt:
            print("\nGoodbye!")
            break
        except Exception as e:
            print(f"Unexpected error: {e}")

if __name__ == "__main__":
    main()</code></pre>

    <h3>Generated Test Code:</h3>
    <pre><code>#!/usr/bin/env python3
"""Unit tests for the Calculator class"""

import unittest
from calculator import Calculator

class TestCalculator(unittest.TestCase):
    """Test cases for Calculator class."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        self.calc = Calculator()
    
    def test_add(self):
        """Test addition operation."""
        self.assertEqual(self.calc.add(2, 3), 5)
        self.assertEqual(self.calc.add(-1, 1), 0)
        self.assertEqual(self.calc.add(0, 0), 0)
        self.assertAlmostEqual(self.calc.add(0.1, 0.2), 0.3, places=7)
    
    def test_subtract(self):
        """Test subtraction operation."""
        self.assertEqual(self.calc.subtract(5, 3), 2)
        self.assertEqual(self.calc.subtract(1, 1), 0)
        self.assertEqual(self.calc.subtract(-1, -1), 0)
    
    def test_multiply(self):
        """Test multiplication operation."""
        self.assertEqual(self.calc.multiply(3, 4), 12)
        self.assertEqual(self.calc.multiply(-2, 3), -6)
        self.assertEqual(self.calc.multiply(0, 5), 0)
    
    def test_divide(self):
        """Test division operation."""
        self.assertEqual(self.calc.divide(10, 2), 5)
        self.assertEqual(self.calc.divide(-6, 3), -2)
    
    def test_divide_by_zero(self):
        """Test division by zero raises ValueError."""
        with self.assertRaises(ValueError):
            self.calc.divide(5, 0)

if __name__ == "__main__":
    unittest.main()</code></pre>

    <h2>Example 2: Agent Event Processing</h2>

    <h3>Event Publishing:</h3>
    <pre><code># Publish agent completion event
await event_bus.publish(AgentEvent(
    event_type=EventType.AGENT_COMPLETED,
    source="python_coder",
    data={
        "generated_files": {
            "main.py": "...",
            "test_main.py": "..."
        },
        "execution_time": 120.5,
        "lines_of_code": 150
    },
    correlation_id="pipeline-abc123",
    metadata={
        "agent_version": "2.0.0",
        "config_type": "CODING"
    }
))</code></pre>

    <h3>Event Subscription:</h3>
    <pre><code>async def handle_agent_completion(event: AgentEvent):
    """Handle agent completion events."""
    logger.info(f"Agent {event.source} completed")
    
    if event.data and "generated_files" in event.data:
        files = event.data["generated_files"]
        logger.info(f"Generated {len(files)} files")
        
        # Update progress tracking
        progress_manager.update_step_completion(
            event.source, 
            len(files)
        )

# Subscribe to agent completion events
event_bus.subscribe(EventType.AGENT_COMPLETED, handle_agent_completion)</code></pre>

    <h2>Example 3: Progress Tracking Implementation</h2>

    <h3>Frontend Progress Component:</h3>
    <pre><code>const ProgressStep: React.FC<{step: PipelineStep}> = ({ step }) => {
  const getStatusIcon = () => {
    switch (step.status) {
      case 'completed':
        return <CheckCircle className="h-5 w-5 text-green-500" />;
      case 'running':
        return <Loader2 className="animate-spin h-5 w-5 text-blue-500" />;
      case 'failed':
        return <XCircle className="h-5 w-5 text-red-500" />;
      default:
        return <Clock className="h-5 w-5 text-gray-400" />;
    }
  };

  const getStatusClass = (status: string) => {
    switch (status) {
      case 'completed':
        return 'border-green-200 bg-green-50';
      case 'running':
        return 'border-blue-200 bg-blue-50';
      case 'failed':
        return 'border-red-200 bg-red-50';
      default:
        return 'border-gray-200 bg-gray-50';
    }
  };

  const getColorClass = (color: string) => {
    const colorMap: Record<string, string> = {
      blue: 'bg-blue-100 text-blue-600',
      green: 'bg-green-100 text-green-600',
      purple: 'bg-purple-100 text-purple-600',
      orange: 'bg-orange-100 text-orange-600',
      red: 'bg-red-100 text-red-600',
      yellow: 'bg-yellow-100 text-yellow-600',
      indigo: 'bg-indigo-100 text-indigo-600'
    };
    return colorMap[color] || 'bg-gray-100 text-gray-600';
  };

  return (
    <div className={`p-4 rounded-2xl border-2 transition-all duration-300 ${getStatusClass(step.status)}`}>
      <div className="flex items-center justify-between">
        <div className="flex items-center space-x-4">
          <div className={`p-2 rounded-xl ${getColorClass(step.color)}`}>
            <step.icon className="h-5 w-5" />
          </div>
          <div>
            <div className="flex items-center space-x-2">
              <span className="font-semibold text-gray-800">{step.name}</span>
              {getStatusIcon()}
            </div>
            <p className="text-sm text-gray-600 mt-1">{step.description}</p>
          </div>
        </div>
        {step.status === 'running' && (
          <div className="text-right">
            <div className="text-lg font-bold text-blue-600">
              {step.progress_percentage.toFixed(0)}%
            </div>
            <div className="text-xs text-gray-500">
              {step.estimated_time && `~${step.estimated_time}s remaining`}
            </div>
          </div>
        )}
      </div>
      
      {step.status === 'running' && step.progress_percentage > 0 && (
        <div className="mt-3">
          <div className="bg-white/50 rounded-full h-2 overflow-hidden">
            <div
              className={`h-2 rounded-full transition-all duration-300 ${
                step.color === 'blue' ? 'bg-blue-500' :
                step.color === 'green' ? 'bg-green-500' :
                step.color === 'purple' ? 'bg-purple-500' :
                step.color === 'orange' ? 'bg-orange-500' :
                step.color === 'red' ? 'bg-red-500' :
                step.color === 'yellow' ? 'bg-yellow-500' :
                step.color === 'indigo' ? 'bg-indigo-500' : 'bg-gray-500'
              }`}
              style={{ width: `${step.progress_percentage}%` }}
            />
          </div>
        </div>
      )}
      
      {step.status === 'failed' && step.error && (
        <div className="mt-3 p-2 bg-red-100 border border-red-200 rounded-lg">
          <p className="text-sm text-red-700">
            <strong>Error:</strong> {step.error}
          </p>
        </div>
      )}
    </div>
  );
};</code></pre>

    <h1 id="best-practices">Best Practices</h1>

    <h2>1. Agent Development Guidelines</h2>

    <h3>Agent Class Structure</h3>
    <pre><code>class CustomAgent(BaseAgent):
    """Follow this structure for new agents."""
    
    @classmethod
    def get_metadata(cls) -> AgentMetadata:
        """Always provide comprehensive metadata."""
        return AgentMetadata(
            name="Custom Agent",
            description="Clear, concise description",
            capabilities=["List specific capabilities"],
            config_type=ConfigType.APPROPRIATE_TYPE,
            dependencies=["List dependencies"],
            version="1.0.0"
        )
    
    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """Always validate input data."""
        # Implement validation logic
        return {"is_valid": True, "warnings": [], "suggestions": []}
    
    def process(self, input_data: Any, context: Dict[str, Any] = None) -> Any:
        """Main processing logic with error handling."""
        try:
            # Validate input
            validation = self.validate_input(input_data)
            if not validation["is_valid"]:
                return {"error": "Invalid input", "validation": validation}
            
            # Process data
            result = self._process_internal(input_data, context)
            
            return {
                "agent": self.metadata.name,
                "success": True,
                "result": result,
                "validation": validation
            }
            
        except Exception as e:
            return {
                "agent": self.metadata.name,
                "success": False,
                "error": str(e)
            }</code></pre>

    <h2>2. Error Handling Strategies</h2>

    <h3>Pipeline Error Recovery</h3>
    <pre><code>async def _execute_single_step(self, step_name: str, input_data: Any, correlation_id: str):
    """Execute with proper error handling."""
    try:
        # Execute agent
        result = agent.process(input_data, context=self._execution_context)
        
        # Publish success event
        await publish_agent_completed(agent.metadata.name, result, correlation_id)
        
        return result
        
    except Exception as e:
        # Update progress with failure
        self._update_step_progress(step_name, "failed", 0)
        
        # Publish failure event
        await publish_agent_failed(agent.metadata.name, str(e), correlation_id)
        
        # Handle based on step configuration
        step_config = self._pipeline_config.get_step(step_name)
        if step_config and step_config.optional:
            # Continue with warning for optional steps
            self.logger.warning(f"Optional step {step_name} failed: {str(e)}")
            return {"error": str(e), "optional": True}
        else:
            # Stop pipeline for required steps
            raise</code></pre>

    <h2>3. Performance Optimization Guidelines</h2>

    <h3>Efficient Event Processing</h3>
    <pre><code># Use async/await for non-blocking operations
async def process_events_efficiently():
    """Process multiple events concurrently."""
    tasks = []
    
    for event in pending_events:
        if asyncio.iscoroutinefunction(handler):
            tasks.append(handler(event))
        else:
            # Run sync handlers in thread pool
            tasks.append(asyncio.get_event_loop().run_in_executor(
                None, handler, event
            ))
    
    # Process all events concurrently
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Handle any failures
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"Event processing failed: {result}")</code></pre>

    <h3>Memory Management</h3>
    <pre><code># Implement cleanup strategies
class ResourceManager:
    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self._cleanup_interval = 3600  # 1 hour
    
    async def periodic_cleanup(self):
        """Periodic cleanup of old resources."""
        while True:
            try:
                # Clean up old events
                if len(self.event_history) > self.max_history:
                    self.event_history = self.event_history[-self.max_history:]
                
                # Clean up old project results
                await self.cleanup_old_projects()
                
                # Clear unused agent instances
                self.agent_factory.clear_unused_instances()
                
            except Exception as e:
                logger.error(f"Cleanup failed: {e}")
            
            await asyncio.sleep(self._cleanup_interval)</code></pre>

    <h2>4. Testing Strategies</h2>

    <h3>Unit Testing for Agents</h3>
    <pre><code>class TestPythonCoderAgent(unittest.TestCase):
    """Comprehensive agent testing."""
    
    def setUp(self):
        """Set up test environment."""
        self.agent = PythonCoderAgent({
            "model": "test-model",
            "temperature": 0.1
        })
    
    def test_input_validation(self):
        """Test input validation logic."""
        # Test valid input
        result = self.agent.validate_input("Create a calculator")
        self.assertTrue(result["is_valid"])
        
        # Test invalid input
        result = self.agent.validate_input("")
        self.assertFalse(result["is_valid"])
    
    def test_code_generation(self):
        """Test code generation functionality."""
        input_data = "Create a simple calculator"
        result = self.agent.process(input_data)
        
        self.assertTrue(result["success"])
        self.assertIn("generated_code", result)
        self.assertIsInstance(result["generated_code"], dict)
    
    @patch('agents.python_coder_agent.autogen.AssistantAgent')
    def test_agent_creation(self, mock_agent):
        """Test agent creation with mocking."""
        agent = self.agent.create_agent()
        mock_agent.assert_called_once()</code></pre>

    <h3>Integration Testing</h3>
    <pre><code>class TestPipelineIntegration(unittest.TestCase):
    """Test complete pipeline execution."""
    
    async def test_full_pipeline_execution(self):
        """Test end-to-end pipeline execution."""
        # Initialize pipeline
        success = agent_manager_v2.initialize_pipeline("default")
        self.assertTrue(success)
        
        # Execute pipeline
        result = await agent_manager_v2.execute_pipeline(
            "Create a todo application",
            correlation_id="test-123"
        )
        
        # Verify results
        self.assertTrue(result["success"])
        self.assertIn("results", result)
        
        # Check that all agents executed
        results = result["results"]
        expected_agents = [
            "requirement_analyst", "python_coder", "code_reviewer",
            "test_generator", "documentation_writer", 
            "deployment_engineer", "ui_designer"
        ]
        
        for agent_name in expected_agents:
            self.assertIn(agent_name, results)</code></pre>

    <h2>5. Monitoring and Logging</h2>

    <h3>Structured Logging</h3>
    <pre><code>import structlog

# Configure structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Usage in agents
logger.info(
    "Agent execution started",
    agent_name="python_coder",
    correlation_id="abc123",
    input_size=len(input_data)
)</code></pre>

    <h3>Performance Monitoring</h3>
    <pre><code>import time
from functools import wraps

def monitor_performance(func):
    """Decorator to monitor function performance."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            logger.info(
                "Function executed successfully",
                function=func.__name__,
                execution_time=execution_time,
                success=True
            )
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            logger.error(
                "Function execution failed",
                function=func.__name__,
                execution_time=execution_time,
                error=str(e),
                success=False
            )
            
            raise
    
    return wrapper

# Usage
@monitor_performance
async def execute_agent(self, agent_name: str, input_data: Any):
    """Execute agent with performance monitoring."""
    # Agent execution logic
    pass</code></pre>

    <div class="conclusion">
        <h2>Conclusion</h2>
        <p>GenXcoder represents a sophisticated approach to AI-powered code generation, leveraging multiple specialized agents working in concert to produce comprehensive software solutions. The system's architecture emphasizes:</p>
        <ul>
            <li><strong>Modularity:</strong> Each component has a specific responsibility</li>
            <li><strong>Scalability:</strong> Event-driven architecture supports concurrent operations</li>
            <li><strong>Reliability:</strong> Comprehensive error handling and recovery mechanisms</li>
            <li><strong>Maintainability:</strong> Clean code structure with extensive documentation</li>
            <li><strong>Performance:</strong> Optimized for real-world usage patterns</li>
        </ul>
        <p>The platform successfully transforms user requirements into production-ready applications, complete with code, tests, documentation, and deployment configurations, making it a powerful tool for rapid application development.</p>
    </div>

    <div class="document-footer">
        <strong>Document Version:</strong> 1.0.0<br>
        <strong>Last Updated:</strong> January 2025<br>
        <strong>Authors:</strong> GenXcoder Development Team<br>
        <strong>Contact:</strong> support@genxcoder.com
    </div>

</body>
</html>
